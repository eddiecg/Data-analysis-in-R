<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Machine Learning Fundamentals: Spam Detection Using a Naive Bayes Classifier | Fundamentals of Data Analysis in R</title>
  <meta name="description" content="<p>This is a collection of tutorials that illustrate how to analyse data in R.
The topics touched on this collection span univariate data analysis, multivariate data analysis, and fundamentals of machine learning.</p>" />
  <meta name="generator" content="bookdown 0.28.1 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Machine Learning Fundamentals: Spam Detection Using a Naive Bayes Classifier | Fundamentals of Data Analysis in R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a collection of tutorials that illustrate how to analyse data in R.
The topics touched on this collection span univariate data analysis, multivariate data analysis, and fundamentals of machine learning.</p>" />
  <meta name="github-repo" content="eddiecg/Data-analysis-in-R" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Machine Learning Fundamentals: Spam Detection Using a Naive Bayes Classifier | Fundamentals of Data Analysis in R" />
  
  <meta name="twitter:description" content="<p>This is a collection of tutorials that illustrate how to analyse data in R.
The topics touched on this collection span univariate data analysis, multivariate data analysis, and fundamentals of machine learning.</p>" />
  

<meta name="author" content="Eddie Cano-Gamez" />


<meta name="date" content="2022-08-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="web-scraping-in-r.html"/>
<link rel="next" href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Fundamentals of Data Analysis in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html"><i class="fa fa-check"></i><b>1</b> Introduction to Programming in R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#calculations-in-r"><i class="fa fa-check"></i><b>1.1</b> Calculations in R</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#variable-assignation-in-r"><i class="fa fa-check"></i><b>1.2</b> Variable assignation in R</a></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#data-types-in-r"><i class="fa fa-check"></i><b>1.3</b> Data types in R</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#numeric-variables"><i class="fa fa-check"></i><b>1.3.1</b> Numeric variables</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#character-variables"><i class="fa fa-check"></i><b>1.3.2</b> Character variables</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#logical-variables"><i class="fa fa-check"></i><b>1.3.3</b> Logical variables</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#categorical-variables-factors"><i class="fa fa-check"></i><b>1.3.4</b> Categorical variables (factors)</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#working-with-multiple-numbers-in-r"><i class="fa fa-check"></i><b>1.4</b> Working with multiple numbers in R</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#vectors"><i class="fa fa-check"></i><b>1.4.1</b> Vectors</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#lists"><i class="fa fa-check"></i><b>1.4.2</b> Lists</a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#matrices"><i class="fa fa-check"></i><b>1.4.3</b> Matrices</a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#data-frames"><i class="fa fa-check"></i><b>1.4.4</b> Data frames</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#manipulating-data-in-r"><i class="fa fa-check"></i><b>1.5</b> Manipulating data in R</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#working-with-lists-of-data-frames"><i class="fa fa-check"></i><b>1.5.1</b> Working with lists of data frames</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#extending-rs-funcitonality-with-libraries"><i class="fa fa-check"></i><b>1.6</b> Extending R’s funcitonality with libraries</a></li>
<li class="chapter" data-level="1.7" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#writing-data-from-r"><i class="fa fa-check"></i><b>1.7</b> Writing data from R</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#writing-human-readable-files"><i class="fa fa-check"></i><b>1.7.1</b> Writing human readable files</a></li>
<li class="chapter" data-level="1.7.2" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#writing-binary-files"><i class="fa fa-check"></i><b>1.7.2</b> Writing binary files</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#reading-data-into-r"><i class="fa fa-check"></i><b>1.8</b> Reading data into R</a></li>
<li class="chapter" data-level="1.9" data-path="introduction-to-programming-in-r.html"><a href="introduction-to-programming-in-r.html#project-work"><i class="fa fa-check"></i><b>1.9</b> Project work</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html"><i class="fa fa-check"></i><b>2</b> Univariate Data Analysis</a>
<ul>
<li class="chapter" data-level="2.1" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#visualising-univariate-data"><i class="fa fa-check"></i><b>2.1</b> Visualising univariate data</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#dot-plot-strip-chart"><i class="fa fa-check"></i><b>2.1.1</b> Dot plot / Strip chart</a></li>
<li class="chapter" data-level="2.1.2" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#histograms"><i class="fa fa-check"></i><b>2.1.2</b> Histograms</a></li>
<li class="chapter" data-level="2.1.3" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#density-plot"><i class="fa fa-check"></i><b>2.1.3</b> Density plot</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#summarising-univariate-data"><i class="fa fa-check"></i><b>2.2</b> Summarising univariate data</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#mean"><i class="fa fa-check"></i><b>2.2.1</b> Mean</a></li>
<li class="chapter" data-level="2.2.2" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#median"><i class="fa fa-check"></i><b>2.2.2</b> Median</a></li>
<li class="chapter" data-level="2.2.3" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#quantiles"><i class="fa fa-check"></i><b>2.2.3</b> Quantiles</a></li>
<li class="chapter" data-level="2.2.4" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#standard-deviation"><i class="fa fa-check"></i><b>2.2.4</b> Standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#comparing-data-to-probability-distributions"><i class="fa fa-check"></i><b>2.3</b> Comparing data to probability distributions</a></li>
<li class="chapter" data-level="2.4" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#box-plots"><i class="fa fa-check"></i><b>2.4</b> Box plots</a></li>
<li class="chapter" data-level="2.5" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#data-as-a-random-sample"><i class="fa fa-check"></i><b>2.5</b> Data as a random sample</a></li>
<li class="chapter" data-level="2.6" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
<li class="chapter" data-level="2.7" data-path="univariate-data-analysis.html"><a href="univariate-data-analysis.html#references"><i class="fa fa-check"></i><b>2.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html"><i class="fa fa-check"></i><b>3</b> Bivariate Data Analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html#visualising-two-variables"><i class="fa fa-check"></i><b>3.1</b> Visualising two variables</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html#scatter-plot"><i class="fa fa-check"></i><b>3.1.1</b> Scatter plot</a></li>
<li class="chapter" data-level="3.1.2" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html#bivariate-box-plots"><i class="fa fa-check"></i><b>3.1.2</b> Bivariate box plots</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html#applying-transformations-to-a-variable"><i class="fa fa-check"></i><b>3.2</b> Applying transformations to a variable</a></li>
<li class="chapter" data-level="3.3" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html#using-ggplot2-to-create-personalised-plots"><i class="fa fa-check"></i><b>3.3</b> Using ggplot2 to create personalised plots</a></li>
<li class="chapter" data-level="3.4" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html#exercises-1"><i class="fa fa-check"></i><b>3.4</b> Exercises</a></li>
<li class="chapter" data-level="3.5" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html#covariance"><i class="fa fa-check"></i><b>3.5</b> Covariance</a></li>
<li class="chapter" data-level="3.6" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html#correlation"><i class="fa fa-check"></i><b>3.6</b> Correlation</a></li>
<li class="chapter" data-level="3.7" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html#predictions-and-linear-models"><i class="fa fa-check"></i><b>3.7</b> Predictions and linear models</a></li>
<li class="chapter" data-level="3.8" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html#correlation-does-not-equal-causation"><i class="fa fa-check"></i><b>3.8</b> Correlation does not equal causation</a></li>
<li class="chapter" data-level="3.9" data-path="bivariate-data-analysis.html"><a href="bivariate-data-analysis.html#exercises-2"><i class="fa fa-check"></i><b>3.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html"><i class="fa fa-check"></i><b>4</b> Multivariate Data Analysis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#exploring-one-variable-at-a-time"><i class="fa fa-check"></i><b>4.1</b> Exploring one variable at a time</a></li>
<li class="chapter" data-level="4.2" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#analysing-all-variables-jointly"><i class="fa fa-check"></i><b>4.2</b> Analysing all variables jointly</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#scatter-plot-matrices"><i class="fa fa-check"></i><b>4.2.1</b> Scatter plot matrices</a></li>
<li class="chapter" data-level="4.2.2" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#correlation-plots"><i class="fa fa-check"></i><b>4.2.2</b> Correlation plots</a></li>
<li class="chapter" data-level="4.2.3" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#the-distance-matrix"><i class="fa fa-check"></i><b>4.2.3</b> The distance matrix</a></li>
<li class="chapter" data-level="4.2.4" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#clustering-and-dendrograms"><i class="fa fa-check"></i><b>4.2.4</b> Clustering and dendrograms</a></li>
<li class="chapter" data-level="4.2.5" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#heatmaps"><i class="fa fa-check"></i><b>4.2.5</b> Heatmaps</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#exercises-3"><i class="fa fa-check"></i><b>4.3</b> Exercises</a></li>
<li class="chapter" data-level="4.4" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#reducing-the-number-of-dimensions"><i class="fa fa-check"></i><b>4.4</b> Reducing the number of dimensions</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#combining-dimensionality-reduction-with-clustering"><i class="fa fa-check"></i><b>4.4.1</b> Combining dimensionality reduction with clustering</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#exercises-4"><i class="fa fa-check"></i><b>4.5</b> Exercises</a></li>
<li class="chapter" data-level="4.6" data-path="multivariate-data-analysis.html"><a href="multivariate-data-analysis.html#references-1"><i class="fa fa-check"></i><b>4.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="web-scraping-in-r.html"><a href="web-scraping-in-r.html"><i class="fa fa-check"></i><b>5</b> Web scraping in R</a>
<ul>
<li class="chapter" data-level="5.1" data-path="web-scraping-in-r.html"><a href="web-scraping-in-r.html#example-scraping-the-imdb-website"><i class="fa fa-check"></i><b>5.1</b> Example: Scraping the IMDB website</a></li>
<li class="chapter" data-level="5.2" data-path="web-scraping-in-r.html"><a href="web-scraping-in-r.html#extracting-variables-using-css-selectors"><i class="fa fa-check"></i><b>5.2</b> Extracting variables using CSS selectors</a></li>
<li class="chapter" data-level="5.3" data-path="web-scraping-in-r.html"><a href="web-scraping-in-r.html#scraping-multiple-fields-from-a-website"><i class="fa fa-check"></i><b>5.3</b> Scraping multiple fields from a website</a></li>
<li class="chapter" data-level="5.4" data-path="web-scraping-in-r.html"><a href="web-scraping-in-r.html#performing-exploratory-data-analysis-eda-on-scraped-data"><i class="fa fa-check"></i><b>5.4</b> Performing exploratory data analysis (EDA) on scraped data</a></li>
<li class="chapter" data-level="5.5" data-path="web-scraping-in-r.html"><a href="web-scraping-in-r.html#exercises-5"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
<li class="chapter" data-level="5.6" data-path="web-scraping-in-r.html"><a href="web-scraping-in-r.html#references-2"><i class="fa fa-check"></i><b>5.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><i class="fa fa-check"></i><b>6</b> Machine Learning Fundamentals: Spam Detection Using a Naive Bayes Classifier</a>
<ul>
<li class="chapter" data-level="6.1" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#visualising-data"><i class="fa fa-check"></i><b>6.1</b> Visualising data</a></li>
<li class="chapter" data-level="6.2" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#pre-processing-data"><i class="fa fa-check"></i><b>6.2</b> Pre-processing data</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#converting-data-to-corpus"><i class="fa fa-check"></i><b>6.2.1</b> Converting data to corpus</a></li>
<li class="chapter" data-level="6.2.2" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cleaning-data"><i class="fa fa-check"></i><b>6.2.2</b> Cleaning data</a></li>
<li class="chapter" data-level="6.2.3" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#visualising-clean-data"><i class="fa fa-check"></i><b>6.2.3</b> Visualising clean data</a></li>
<li class="chapter" data-level="6.2.4" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#tokenising"><i class="fa fa-check"></i><b>6.2.4</b> Tokenising</a></li>
<li class="chapter" data-level="6.2.5" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#dividing-data-into-training-and-testing-set"><i class="fa fa-check"></i><b>6.2.5</b> Dividing data into training and testing set</a></li>
<li class="chapter" data-level="6.2.6" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#correcting-data-sparsity"><i class="fa fa-check"></i><b>6.2.6</b> Correcting data sparsity</a></li>
<li class="chapter" data-level="6.2.7" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#converting-data-to-word-appearance-table"><i class="fa fa-check"></i><b>6.2.7</b> Converting data to word appearance table</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#predicting-spam-and-non-spam"><i class="fa fa-check"></i><b>6.3</b> Predicting spam and non-spam</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#training-classifier"><i class="fa fa-check"></i><b>6.3.1</b> Training classifier</a></li>
<li class="chapter" data-level="6.3.2" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#testing-classifier"><i class="fa fa-check"></i><b>6.3.2</b> Testing classifier</a></li>
<li class="chapter" data-level="6.3.3" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#evaluating-performance"><i class="fa fa-check"></i><b>6.3.3</b> Evaluating performance</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#discussion"><i class="fa fa-check"></i><b>6.4</b> Discussion</a></li>
<li class="chapter" data-level="6.5" data-path="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#references-3"><i class="fa fa-check"></i><b>6.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><i class="fa fa-check"></i><b>7</b> Machine Learning Fundamentals: Predicting Variables Using Neural Networks</a>
<ul>
<li class="chapter" data-level="7.1" data-path="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html#normalising-data"><i class="fa fa-check"></i><b>7.1</b> Normalising data</a></li>
<li class="chapter" data-level="7.2" data-path="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html#visualising-data-1"><i class="fa fa-check"></i><b>7.2</b> Visualising data</a></li>
<li class="chapter" data-level="7.3" data-path="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html#creating-neural-network"><i class="fa fa-check"></i><b>7.3</b> Creating neural network</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html#spliting-data-into-training-and-testing-sets"><i class="fa fa-check"></i><b>7.3.1</b> Spliting data into training and testing sets</a></li>
<li class="chapter" data-level="7.3.2" data-path="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html#training-neural-network"><i class="fa fa-check"></i><b>7.3.2</b> Training neural network</a></li>
<li class="chapter" data-level="7.3.3" data-path="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html#testing-neural-network"><i class="fa fa-check"></i><b>7.3.3</b> Testing neural network</a></li>
<li class="chapter" data-level="7.3.4" data-path="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html#evaluating-performance-1"><i class="fa fa-check"></i><b>7.3.4</b> Evaluating performance</a></li>
<li class="chapter" data-level="7.3.5" data-path="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html#improving-performance-by-adding-hidden-nodes"><i class="fa fa-check"></i><b>7.3.5</b> Improving performance by adding hidden nodes</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html#conclusions"><i class="fa fa-check"></i><b>7.4</b> Conclusions</a></li>
<li class="chapter" data-level="7.5" data-path="machine-learning-fundamentals-predicting-variables-using-neural-networks.html"><a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html#references-4"><i class="fa fa-check"></i><b>7.5</b> References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentals of Data Analysis in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> Machine Learning Fundamentals: Spam Detection Using a Naive Bayes Classifier<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In the previous sessions we learnt how to read data (from files or from public websites) into R, how to process it, explore it and perform some basic analysis for one, two or multiple variables. Now that you know how to do all of this, you are prepared to look at the final steps of data analysis: using the data to find new knowledge and apply it to relevant objectives such as finding patterns or predicting outcomes. This falls under the scope of machine learning, a discipline which combines statistics, mathematics and computer science to make sense of data. The two most tasks in types of machine learning are:</p>
<ol style="list-style-type: upper-alpha">
<li><p>Clustering: Finding if any patterns or subgroups exist in our data. We learnt a bit of this in our previous session on heatmaps and dendrograms.</p></li>
<li><p>Classification: Clasifying an individual observation into one of the possible groups of classes. There are multiple applications of this in the real world. For example finding if a bank transaction is normal or fraud, determining if a message is normal or spam, finding whether a star contains exoplanets or not, classifying cancer patients into different types of cancer, etc…</p></li>
</ol>
<p>In this session we will use a specific type of machine learning called “Naive Bayes” to classify SMS messages into normal or spam.</p>
<p>Before starting this session we need to install several R libraries. Some of these libraries are designed to work with text data (remember messages are by definition in a text format) and others contain machine learning functions. To install these libraries, simply run the following lines of code.</p>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb423-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;tm&quot;</span>)</span>
<span id="cb423-2"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb423-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;e1071&quot;</span>)</span>
<span id="cb423-3"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb423-3" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;gmodels&quot;</span>)</span>
<span id="cb423-4"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb423-4" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;rlang&quot;</span>)</span></code></pre></div>
<p>Let’s now load the libraries.</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb424-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tm)</span>
<span id="cb424-2"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb424-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(wordcloud)</span>
<span id="cb424-3"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb424-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rlang)</span>
<span id="cb424-4"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb424-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb424-5"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb424-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gmodels)</span>
<span id="cb424-6"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb424-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rafalib)</span></code></pre></div>
<p>You can find the data for this session in the “Data” directory, along with the other materials for this course. The file is called “sms_spam.csv”. Let’s read this into R. Note that I am asking R not to transform text into factors, because messages are mostly text.</p>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb425-1" aria-hidden="true" tabindex="-1"></a>sms_raw <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;./Data/sms_spam.csv&quot;</span>, <span class="at">stringsAsFactors =</span> F)</span></code></pre></div>
<p>We use the function str() to find the structure of this data</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb426-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(sms_raw)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    5559 obs. of  2 variables:
##  $ type: chr  &quot;ham&quot; &quot;ham&quot; &quot;ham&quot; &quot;spam&quot; ...
##  $ text: chr  &quot;Hope you are having a good week. Just checking in&quot; &quot;K..give back my thanks.&quot; &quot;Am also doing in cbe only. But have to pay.&quot; &quot;complimentary 4 STAR Ibiza Holiday or £10,000 cash needs your URGENT collection. 09066364349 NOW from Landline &quot;| __truncated__ ...</code></pre>
<p>R tells us that we have two variables:</p>
<ol style="list-style-type: decimal">
<li>A series of 5559 text (SMS) messages</li>
<li>A list which tells us which of these messges are spam and which are normal (“ham”). This has been manually determined by the people who collected the data.</li>
</ol>
<p>Let’s transform the spam/ham labels into a factor, since these really are two categories.</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb428-1" aria-hidden="true" tabindex="-1"></a>sms_raw<span class="sc">$</span>type <span class="ot">&lt;-</span> <span class="fu">factor</span>(sms_raw<span class="sc">$</span>type)</span></code></pre></div>
<p>Now let’s count how many spam and how many “ham” messges there are:</p>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb429-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(sms_raw<span class="sc">$</span>type)</span></code></pre></div>
<pre><code>## 
##  ham spam 
## 4812  747</code></pre>
<p>The majority of them (~ 86%) are normal messages, and only 14% are spam.</p>
<div id="visualising-data" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Visualising data<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#visualising-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s now visualise the data. Because this data is in a text format, we cannot create histograms or scatter plots for it. Instead, let’s use a word cloud to find which words are used most frequently. Because there are almost 6 thousand messages and thosands of words, we ask R to only show us the 50 most common words.</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb431-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wordcloud</span>(sms_raw<span class="sc">$</span>text, <span class="at">max.words =</span> <span class="dv">50</span>, <span class="at">random.order =</span> F)</span></code></pre></div>
<p><img src="_main_files/figure-html/wordcloud%20sms_raw-1.png" width="672" /></p>
<p>Now, let’s use the function subset() to separate the data in two: a list of normal messages and a list of spam messages.</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb432-1" aria-hidden="true" tabindex="-1"></a>spam <span class="ot">&lt;-</span> <span class="fu">subset</span>(sms_raw, type<span class="sc">==</span><span class="st">&quot;spam&quot;</span>)</span>
<span id="cb432-2"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb432-2" aria-hidden="true" tabindex="-1"></a>ham <span class="ot">&lt;-</span> <span class="fu">subset</span>(sms_raw, type<span class="sc">==</span><span class="st">&quot;ham&quot;</span>)</span></code></pre></div>
<p>Let’s now repeat the word cloud separately for each group. In this way, we can compare the word composition of spam and non-spam messages.</p>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb433-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mypar</span>(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb433-2"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb433-2" aria-hidden="true" tabindex="-1"></a><span class="fu">wordcloud</span>(spam<span class="sc">$</span>text, <span class="at">max.words =</span> <span class="dv">50</span>, <span class="at">scale=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="fl">0.5</span>), <span class="at">random.order =</span> F)</span>
<span id="cb433-3"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb433-3" aria-hidden="true" tabindex="-1"></a><span class="fu">wordcloud</span>(ham<span class="sc">$</span>text, <span class="at">max.words =</span> <span class="dv">50</span>, <span class="at">scale=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="fl">0.5</span>), <span class="at">random.order =</span> F)</span></code></pre></div>
<p><img src="_main_files/figure-html/wordclouds%20spam%20and%20ham-1.png" width="672" /></p>
<p>We can already see some major differences between both types of message. Spam messages use words as “call”, “free”, “reply” and even “£200” (beause what they want is for you to call them back or to make you think you’ve won something). Normal messges between humans talk about much more emotional matters. For example, in normal messages we see words like “can”, “know”, “sorry”, “good” or even “home”.</p>
<p>If these messages are so different, can we use their word composition to separate them or create a spam filter? We will try to apply machine learning to achieve this.</p>
</div>
<div id="pre-processing-data" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Pre-processing data<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#pre-processing-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The first thing we need to do is putting the data in the right format. Machine learning uses statistics, and statistics can only deal with numbers or proportions. Thus, we will have to convert these messages into a quantitative format.</p>
<div id="converting-data-to-corpus" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Converting data to corpus<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#converting-data-to-corpus" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We start by converting our 6000 messages into a “corpus”. A corpus is a list, where each element of the list is a series of words. We use the function Corpus().</p>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb434-1" aria-hidden="true" tabindex="-1"></a>sms_corpus <span class="ot">&lt;-</span> <span class="fu">Corpus</span>(<span class="fu">VectorSource</span>(sms_raw<span class="sc">$</span>text))</span></code></pre></div>
<p>We can use the function “inspect()” to look at the first three messages in the corpus:</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb435-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(sms_corpus[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>])</span></code></pre></div>
<pre><code>## &lt;&lt;SimpleCorpus&gt;&gt;
## Metadata:  corpus specific: 1, document level (indexed): 0
## Content:  documents: 3
## 
## [1] Hope you are having a good week. Just checking in K..give back my thanks.                           Am also doing in cbe only. But have to pay.</code></pre>
</div>
<div id="cleaning-data" class="section level3 hasAnchor" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Cleaning data<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cleaning-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now we need to clean the data and remove all the noise and unnecessary words. There can be a lot of unnecessary words and signs in 6 thousand messages! The first problem with words is that R is case sensitive, so words starting with upper case or lower case will be seen by R as different things, even if they are the exact same word. Thus, let’s transf all the words to lower case using the tm_map() function and specifying we want lower case. We’ll store our clean body of words in the variable “corpus_clean”.</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb437-1" aria-hidden="true" tabindex="-1"></a>corpus_clean <span class="ot">&lt;-</span> <span class="fu">tm_map</span>(sms_corpus, tolower)</span></code></pre></div>
<p>Next, let’s remove all the numbers and keep only words.</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb438-1" aria-hidden="true" tabindex="-1"></a>corpus_clean <span class="ot">&lt;-</span> <span class="fu">tm_map</span>(corpus_clean, removeNumbers)</span></code></pre></div>
<p>Some words are absolutely useless for classifying messages. For example, stop words such as “to”,“and”,“but”,“or”, etc… give us very little information and usually appear a lot of times, hence taking up too much memory. Let’s use tm_map() to remove all stop words.</p>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb439-1" aria-hidden="true" tabindex="-1"></a>corpus_clean <span class="ot">&lt;-</span> <span class="fu">tm_map</span>(corpus_clean, removeWords, <span class="fu">stopwords</span>())</span></code></pre></div>
<p>Now let’s also remove all the punctuation marks (dots, commas, quotes, etc…).</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb440-1" aria-hidden="true" tabindex="-1"></a>corpus_clean <span class="ot">&lt;-</span> <span class="fu">tm_map</span>(corpus_clean, removePunctuation)</span></code></pre></div>
<p>Finally, let’s remove the extra white space, because often people make typos when composing messages and hit the space key multiple times.</p>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb441-1" aria-hidden="true" tabindex="-1"></a>corpus_clean <span class="ot">&lt;-</span> <span class="fu">tm_map</span>(corpus_clean, stripWhitespace)</span></code></pre></div>
<p>Let’s have a look at our final, clean set of words.</p>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb442-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(corpus_clean[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>])</span></code></pre></div>
<pre><code>## &lt;&lt;SimpleCorpus&gt;&gt;
## Metadata:  corpus specific: 1, document level (indexed): 0
## Content:  documents: 5
## 
## [1] hope good week just checking                                                                        
## [2] kgive back thanks                                                                                   
## [3]  also cbe pay                                                                                       
## [4] complimentary star ibiza holiday £ cash needs urgent collection now landline lose boxskwpppm        
## [5] okmail dear dave final notice collect tenerife holiday cash award call landline tcs sae box cwwx ppm</code></pre>
<p>Note how a lot of words dissappeared and now all the letters are lower case.</p>
</div>
<div id="visualising-clean-data" class="section level3 hasAnchor" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> Visualising clean data<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#visualising-clean-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s create a new word cloud, but now using the clean data.</p>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb444-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb444-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wordcloud</span>(corpus_clean, <span class="at">min.freq =</span> <span class="dv">40</span>, <span class="at">scale=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="fl">0.5</span>), <span class="at">random.order =</span> F)</span></code></pre></div>
<p><img src="_main_files/figure-html/wordcloud%20corpus_clean-1.png" width="672" /></p>
</div>
<div id="tokenising" class="section level3 hasAnchor" number="6.2.4">
<h3><span class="header-section-number">6.2.4</span> Tokenising<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#tokenising" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now comes the most important part: transforming our text data to something quantitative (ie. numbers). The way we do this is by counting how many times each word appears in each message. This will result in a “word count matrix”. In other words, we will construct a matrix in which every row is a message and every column is a word. Each element of the matrix is the number of times that word appeared in this message.</p>
<p>These type of matrix is sometimes called “document term matrix”. Let’s use R’s function DocumentTermMatrix() to convert our clean data into numbers. This processed is often referred to as “tokenising”.</p>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb445-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb445-1" aria-hidden="true" tabindex="-1"></a>sms_dtm <span class="ot">&lt;-</span> <span class="fu">DocumentTermMatrix</span>(corpus_clean)</span></code></pre></div>
</div>
<div id="dividing-data-into-training-and-testing-set" class="section level3 hasAnchor" number="6.2.5">
<h3><span class="header-section-number">6.2.5</span> Dividing data into training and testing set<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#dividing-data-into-training-and-testing-set" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now we are ready to start classifying the messages. As you may have learnt in the theoretical session, the way machine learning work is the following:</p>
<ol style="list-style-type: decimal">
<li>The algorithm is “trained” on a very big data set. Using this data, it will find the patterns that characterise spam and normal messages</li>
<li>The algorithm is applied to new (test) data and classifies each new message as normal or spam.</li>
<li>We can use these results to analyse how the algorithm performed.</li>
</ol>
<p>Let’s first divide the messages in two groups: training and test. We do this on the raw data, the corpus and the word count matrix.</p>
<ol style="list-style-type: upper-alpha">
<li>Training data set: This set will contain 75% of the messages (messages 1 to 4169):</li>
</ol>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb446-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb446-1" aria-hidden="true" tabindex="-1"></a>sms_raw_train <span class="ot">&lt;-</span> sms_raw[<span class="dv">1</span><span class="sc">:</span><span class="dv">4169</span>,]</span>
<span id="cb446-2"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb446-2" aria-hidden="true" tabindex="-1"></a>sms_corpus_train <span class="ot">&lt;-</span> corpus_clean[<span class="dv">1</span><span class="sc">:</span><span class="dv">4169</span>]</span>
<span id="cb446-3"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb446-3" aria-hidden="true" tabindex="-1"></a>sms_dtm_train <span class="ot">&lt;-</span> sms_dtm[<span class="dv">1</span><span class="sc">:</span><span class="dv">4169</span>,]</span></code></pre></div>
<ol start="2" style="list-style-type: upper-alpha">
<li>Test data set: This set will contain 25% of the messages (messages 4170 to 5559):</li>
</ol>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb447-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb447-1" aria-hidden="true" tabindex="-1"></a>sms_raw_test <span class="ot">&lt;-</span> sms_raw[<span class="dv">4170</span><span class="sc">:</span><span class="dv">5559</span>,]</span>
<span id="cb447-2"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb447-2" aria-hidden="true" tabindex="-1"></a>sms_corpus_test <span class="ot">&lt;-</span> corpus_clean[<span class="dv">4170</span><span class="sc">:</span><span class="dv">5559</span>]</span>
<span id="cb447-3"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb447-3" aria-hidden="true" tabindex="-1"></a>sms_dtm_test <span class="ot">&lt;-</span> sms_dtm[<span class="dv">4170</span><span class="sc">:</span><span class="dv">5559</span>,]</span></code></pre></div>
</div>
<div id="correcting-data-sparsity" class="section level3 hasAnchor" number="6.2.6">
<h3><span class="header-section-number">6.2.6</span> Correcting data sparsity<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#correcting-data-sparsity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There is one last problem we need to solve before building our machine learning model. Because so many words exist in the English languge (just look at the size of any dictionary!), chances are there will be a lot of words that only appear in one, two or three of the messages. Theses words are not useful: they will not help us differentiate spam from normal. In statistics this is called “sparsity”: when a very big part of a matrix is full of zeros (in this case, words that appear zero times in most messages). We should remove this sparsity. To do that, let’s restrict our data to frequent words only. All words that appear in less than 5 messages will be discarded. Frequent words can be found using the function findFreqTerms().</p>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb448-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb448-1" aria-hidden="true" tabindex="-1"></a>sms_dict <span class="ot">&lt;-</span> <span class="fu">findFreqTerms</span>(sms_dtm_train, <span class="dv">5</span>)</span></code></pre></div>
<p>Let’s only keep these frequent words</p>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb449-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb449-1" aria-hidden="true" tabindex="-1"></a>sms_train <span class="ot">&lt;-</span> <span class="fu">DocumentTermMatrix</span>(sms_corpus_train, <span class="fu">list</span>(<span class="at">dictionary=</span>sms_dict))</span>
<span id="cb449-2"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb449-2" aria-hidden="true" tabindex="-1"></a>sms_test <span class="ot">&lt;-</span> <span class="fu">DocumentTermMatrix</span>(sms_corpus_test, <span class="fu">list</span>(<span class="at">dictionary=</span>sms_dict))</span></code></pre></div>
</div>
<div id="converting-data-to-word-appearance-table" class="section level3 hasAnchor" number="6.2.7">
<h3><span class="header-section-number">6.2.7</span> Converting data to word appearance table<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#converting-data-to-word-appearance-table" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>At this point, we have create a matrix with words as columns and messages as rows. However, to make things simpler we will restrict our matrix to only two values: if a word appears inside a message the entry is set to “Yes” (1). If it doesn’t, to “No” (0).</p>
<p>This function will convert the word counts to YES and NOs.</p>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb450-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb450-1" aria-hidden="true" tabindex="-1"></a>convert_counts <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb450-2"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb450-2" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(x <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb450-3"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb450-3" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">factor</span>(x, <span class="at">levels=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">labels=</span><span class="fu">c</span>(<span class="st">&quot;No&quot;</span>,<span class="st">&quot;Yes&quot;</span>))</span>
<span id="cb450-4"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb450-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(x)</span>
<span id="cb450-5"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb450-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Let’s apply it to both our training and our test data.</p>
<div class="sourceCode" id="cb451"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb451-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb451-1" aria-hidden="true" tabindex="-1"></a>sms_train <span class="ot">&lt;-</span> <span class="fu">apply</span>(sms_train, <span class="at">MARGIN =</span> <span class="dv">2</span>, convert_counts)</span>
<span id="cb451-2"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb451-2" aria-hidden="true" tabindex="-1"></a>sms_test <span class="ot">&lt;-</span> <span class="fu">apply</span>(sms_test, <span class="at">MARGIN =</span> <span class="dv">2</span>, convert_counts)</span></code></pre></div>
<p>Finally, let’s have a look at the data.</p>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb452-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb452-1" aria-hidden="true" tabindex="-1"></a>sms_train[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span></code></pre></div>
<pre><code>##     Terms
## Docs checking good  hope  just  week  back  thanks also  pay   cash 
##   1  &quot;Yes&quot;    &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; &quot;No&quot;  &quot;No&quot;   &quot;No&quot;  &quot;No&quot;  &quot;No&quot; 
##   2  &quot;No&quot;     &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;Yes&quot; &quot;Yes&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot; 
##   3  &quot;No&quot;     &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;   &quot;Yes&quot; &quot;Yes&quot; &quot;No&quot; 
##   4  &quot;No&quot;     &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;   &quot;No&quot;  &quot;No&quot;  &quot;Yes&quot;
##   5  &quot;No&quot;     &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;   &quot;No&quot;  &quot;No&quot;  &quot;Yes&quot;
##   6  &quot;No&quot;     &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;   &quot;No&quot;  &quot;No&quot;  &quot;No&quot; 
##   7  &quot;No&quot;     &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;   &quot;No&quot;  &quot;No&quot;  &quot;No&quot; 
##   8  &quot;No&quot;     &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;   &quot;No&quot;  &quot;No&quot;  &quot;No&quot; 
##   9  &quot;No&quot;     &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;   &quot;No&quot;  &quot;No&quot;  &quot;No&quot; 
##   10 &quot;No&quot;     &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;   &quot;No&quot;  &quot;No&quot;  &quot;No&quot;</code></pre>
<p>Now we have a matrix of Y and N which tells us which message contains which word. There are 1218 words in this matrix, so you can think of it as a space with about 1200 dimensions (each word is a dimension)! Now we are ready to do machine learning!</p>
</div>
</div>
<div id="predicting-spam-and-non-spam" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Predicting spam and non-spam<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#predicting-spam-and-non-spam" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="training-classifier" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Training classifier<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#training-classifier" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We use the YES/NO data to “train” a classifier. The type of classifier we will work with in this session is called “Naive Bayes”. The way this algorithm works involves advanced statistics. Some of this will be explained during the theoretical session. However, in general terms we find out which words are contianed in a message and which words are not, based on this evidence we calculate the probability that this message is spam or normal. If this probability is high, we say that the message is spam. If it is low, we say that the message is normal. We repeat this for every messag in the data set.</p>
<p>Let’s use the training data to “train” our naive bayes algorithm. All you need to do is use the naiveBayes function as follows:</p>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb454-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb454-1" aria-hidden="true" tabindex="-1"></a>sms_classifier <span class="ot">&lt;-</span> <span class="fu">naiveBayes</span>(sms_train, sms_raw_train<span class="sc">$</span>type)</span></code></pre></div>
<p>Now the algorithm has been trained. In other words, it has looked at the data and found which words appear in spam and in normal messages, then it has calculated probabilities for each of them.</p>
</div>
<div id="testing-classifier" class="section level3 hasAnchor" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Testing classifier<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#testing-classifier" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now we can apply the algorithm we just trained on the remaining 25% of the data (the test set). Is our clasifier able to predict which messages are spam and which are not? To make this prediction we simply use the function “predict” followed by the variable in which our trained model is stored. This step can take a few seconds to run. After all, R is using thousands of words to predict if each message is or isn’t spam!</p>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb455-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb455-1" aria-hidden="true" tabindex="-1"></a>sms_predicted <span class="ot">&lt;-</span> <span class="fu">predict</span>(sms_classifier, sms_test)</span></code></pre></div>
</div>
<div id="evaluating-performance" class="section level3 hasAnchor" number="6.3.3">
<h3><span class="header-section-number">6.3.3</span> Evaluating performance<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#evaluating-performance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s find out how good our predictions were. We use the function CrossTable to compare the actual class of each message (spam or normal, as determined manually by reserachers) with the class we predicted them to have.</p>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb456-1"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb456-1" aria-hidden="true" tabindex="-1"></a><span class="fu">CrossTable</span>(sms_predicted, sms_raw_test<span class="sc">$</span>type,</span>
<span id="cb456-2"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb456-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">prop.chisq =</span> <span class="cn">FALSE</span>, <span class="at">prop.t =</span><span class="cn">FALSE</span>, </span>
<span id="cb456-3"><a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#cb456-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">dnn =</span> <span class="fu">c</span>(<span class="st">&quot;predicted&quot;</span>,<span class="st">&quot;actual&quot;</span>))</span></code></pre></div>
<pre><code>## 
##  
##    Cell Contents
## |-------------------------|
## |                       N |
## |           N / Row Total |
## |           N / Col Total |
## |-------------------------|
## 
##  
## Total Observations in Table:  1390 
## 
##  
##              | actual 
##    predicted |       ham |      spam | Row Total | 
## -------------|-----------|-----------|-----------|
##          ham |      1203 |        32 |      1235 | 
##              |     0.974 |     0.026 |     0.888 | 
##              |     0.997 |     0.175 |           | 
## -------------|-----------|-----------|-----------|
##         spam |         4 |       151 |       155 | 
##              |     0.026 |     0.974 |     0.112 | 
##              |     0.003 |     0.825 |           | 
## -------------|-----------|-----------|-----------|
## Column Total |      1207 |       183 |      1390 | 
##              |     0.868 |     0.132 |           | 
## -------------|-----------|-----------|-----------|
## 
## </code></pre>
<p>You can see that 99.7% of normal messages were detected by our fileter as normal. Only 4 out of more than one thousand normal messags were misclassified as spam. This is a really good performance. On the other hand, about 82.5% of spam messages were correctly labeled as spam. Approximately 32 out of 180 spam messages were misclassified as normal. This performance is good, but could definitely be improved!</p>
<p>Now you know a bit more about how machine learning is used with different comercial and scientific purposes. In this case, to build a spam filter. There are many more machine learning techniques, some of them incredibly accurate and complex. They can be (and in fact) are applied all the time to solve all sorts of problems. Examples of this are recommendations displayed to you on Google, Facebook or Amazon; studying which regions of the brain are active when people perform different tasks; classifying cancers into groups; or performing language processing (for example in devices capable of translating from one language to another in real time).</p>
</div>
</div>
<div id="discussion" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Discussion<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#discussion" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Can you think of any other applications of machine learning? In which ways do you think machine learning is changing our daily lives? Are these changes positive or negative? What are their implications?</p>
</div>
<div id="references-3" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> References<a href="machine-learning-fundamentals-spam-detection-using-a-naive-bayes-classifier.html#references-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This turotial was adapted from:</p>
<ol style="list-style-type: decimal">
<li>Lantz B. (2013). Chapter 4. Probabilistic learning and classification using Naive Bayes. In Machine Learning with R. Birmingham: Packt Publishing.</li>
</ol>
<p>SMS data comes from the study:</p>
<ol start="2" style="list-style-type: decimal">
<li>Gomez-Hidalgo JM, Almeida TA and Yamakami A. (2012). On the validity of a new SMS spam collection. Proceedings of the 11th international conference on machine learning and applications.</li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="web-scraping-in-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="machine-learning-fundamentals-predicting-variables-using-neural-networks.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/06-Machine-learning-for-spam-detection.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
